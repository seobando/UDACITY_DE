{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/2d/2e39f9a023479ea798eed4351cd66f163ce61e00c717e03c37109f00c0f2/findspark-1.4.2-py2.py3-none-any.whl\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://2468c66a9737:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Sparkify</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f5e8af626a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar Pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Sparkify\").master(\"local[*]\").getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType, IntegerType, TimestampType, LongType "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Process song data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get filepath to song data file\n",
    "song_data = \"input/song_data/*/*/*/*.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_schema = StructType([\n",
    "    StructField(\"artist_id\", StringType()),\n",
    "    StructField(\"artist_latitude\", DoubleType()),\n",
    "    StructField(\"artist_location\", StringType()),\n",
    "    StructField(\"artist_longitude\", StringType()),\n",
    "    StructField(\"artist_name\", StringType()),\n",
    "    StructField(\"duration\", DoubleType()),\n",
    "    StructField(\"num_songs\", IntegerType()),\n",
    "    StructField(\"song_id\", IntegerType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"year\", IntegerType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read song data file\n",
    "df = spark.read.json(song_data,schema=song_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artist_id',\n",
       " 'artist_latitude',\n",
       " 'artist_location',\n",
       " 'artist_longitude',\n",
       " 'artist_name',\n",
       " 'duration',\n",
       " 'num_songs',\n",
       " 'song_id',\n",
       " 'title',\n",
       " 'year']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns to create songs table\n",
    "songs_table = (df\n",
    "               .select(col(\"song_id\")\n",
    "                       ,col(\"title\")\n",
    "                       ,col(\"artist_id\")\n",
    "                       ,col(\"year\")\n",
    "                       ,col(\"duration\"))\n",
    "               .dropDuplicates()\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    " # write songs table to parquet files partitioned by year and artist\n",
    "songs_table.write.partitionBy(\"year\",\"artist_id\").parquet(\"output/songs_table.parquet/\" , mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+---------+----+--------+\n",
      "|song_id|title|artist_id|year|duration|\n",
      "+-------+-----+---------+----+--------+\n",
      "|   null| null|     null|null|    null|\n",
      "+-------+-----+---------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns to create artists table\n",
    "artists_table = (df\n",
    "               .select(col(\"artist_id\")\n",
    "                       ,col(\"artist_name\")\n",
    "                       ,col(\"artist_location\")\n",
    "                       ,col(\"artist_latitude\")\n",
    "                       ,col(\"artist_longitude\"))\n",
    "               .dropDuplicates()\n",
    "              ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write artists table to parquet files\n",
    "artists_table.write.parquet(\"output/artists_table.parquet/\" , mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+---------------+---------------+----------------+\n",
      "|         artist_id|         artist_name|artist_location|artist_latitude|artist_longitude|\n",
      "+------------------+--------------------+---------------+---------------+----------------+\n",
      "|ARI3BMM1187FB4255E|        Alice Stuart|     Washington|        38.8991|         -77.029|\n",
      "|ARWB3G61187FB49404|         Steve Morse| Hamilton, Ohio|           null|            null|\n",
      "|ARKULSX1187FB45F84|              Trafik|           Utah|       39.49974|      -111.54732|\n",
      "|ARHHO3O1187B989413|           Bob Azzam|               |           null|            null|\n",
      "|ARAGB2O1187FB3A161|Pucho & His Latin...|               |           null|            null|\n",
      "+------------------+--------------------+---------------+---------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_table.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Process log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get filepath to log data file\n",
    "log_data = \"input/log-data/*.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "log_schema = StructType([\n",
    "    StructField(\"artist\", StringType()),\n",
    "    StructField(\"auth\", DoubleType()),\n",
    "    StructField(\"first_name\", StringType()),\n",
    "    StructField(\"gender\", StringType()),\n",
    "    StructField(\"item_in_session\", LongType()),\n",
    "    StructField(\"last_name\", StringType()),\n",
    "    StructField(\"length\", DoubleType()),\n",
    "    StructField(\"level\", StringType()),\n",
    "    StructField(\"location\", StringType()),\n",
    "    StructField(\"method\", StringType()),\n",
    "    StructField(\"page\", StringType()),\n",
    "    StructField(\"registration\", DoubleType()),\n",
    "    StructField(\"session_id\", LongType()),\n",
    "    StructField(\"song\", StringType()),\n",
    "    StructField(\"status\", LongType()),\n",
    "    StructField(\"ts\", LongType()),\n",
    "    StructField(\"user_agent\", StringType()),\n",
    "    StructField(\"user_id\", StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read log data file\n",
    "df = spark.read.json(log_data,schema= log_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artist',\n",
       " 'auth',\n",
       " 'first_name',\n",
       " 'gender',\n",
       " 'item_in_session',\n",
       " 'last_name',\n",
       " 'length',\n",
       " 'level',\n",
       " 'location',\n",
       " 'method',\n",
       " 'page',\n",
       " 'registration',\n",
       " 'session_id',\n",
       " 'song',\n",
       " 'status',\n",
       " 'ts',\n",
       " 'user_agent',\n",
       " 'user_id']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringType,\n",
       " DoubleType,\n",
       " StringType,\n",
       " StringType,\n",
       " LongType,\n",
       " StringType,\n",
       " DoubleType,\n",
       " StringType,\n",
       " StringType,\n",
       " StringType,\n",
       " StringType,\n",
       " DoubleType,\n",
       " LongType,\n",
       " StringType,\n",
       " LongType,\n",
       " LongType,\n",
       " StringType,\n",
       " StringType]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types = [f.dataType for f in df.schema.fields]\n",
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# filter by actions for song plays\n",
    "df = df.filter(\"page == 'NextSong'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns for users table    \n",
    "users_table = (df.select(col(\"user_id\")\n",
    "                         ,col(\"first_name\")\n",
    "                         ,col(\"last_name\")\n",
    "                         ,col(\"gender\")\n",
    "                         ,col(\"level\")\n",
    "                        )\n",
    "               .dropDuplicates()\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "users_table.write.parquet(\"output/users_table.parquet/\" , mode=\"overwrite\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create timestamp column from original timestamp column\n",
    "get_timestamp = udf(lambda x: datetime.fromtimestamp(x/1000).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "df = df.withColumn('timestamp', get_timestamp('ts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create datetime column from original timestamp column\n",
    "get_datetime = udf(lambda x: datetime.fromtimestamp(x/1000).strftime('%Y-%m-%d'))\n",
    "df = df.withColumn('datetime', get_datetime('ts'))\n",
    "df = (df\n",
    "      .withColumnRenamed(\"ts\",\"start_time\")\n",
    "      .withColumn('hour',hour(\"timestamp\"))\n",
    "      .withColumn('day',dayofmonth(\"datetime\"))\n",
    "      .withColumn('week',weekofyear(\"datetime\"))\n",
    "      .withColumn('month',month(\"datetime\"))\n",
    "      .withColumn('year',year(\"datetime\"))\n",
    "      .withColumn('weekday',dayofweek(\"datetime\"))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns to create time table\n",
    "time_table = (df.select(col(\"start_time\")\n",
    "                      ,col(\"hour\")\n",
    "                      ,col(\"day\")\n",
    "                      ,col(\"week\")\n",
    "                      ,col(\"month\")\n",
    "                      ,col(\"year\")\n",
    "                      ,col(\"weekday\")\n",
    "                      )\n",
    "              .dropDuplicates()\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+---+----+-----+----+-------+\n",
      "|   start_time|hour|day|week|month|year|weekday|\n",
      "+-------------+----+---+----+-----+----+-------+\n",
      "|1542795222796|  10| 21|  47|   11|2018|      4|\n",
      "|1542799276796|  11| 21|  47|   11|2018|      4|\n",
      "|1542195401796|  11| 14|  46|   11|2018|      4|\n",
      "|1543441920796|  21| 28|  48|   11|2018|      4|\n",
      "|1541407889796|   8|  5|  45|   11|2018|      2|\n",
      "+-------------+----+---+----+-----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write time table to parquet files partitioned by year and month\n",
    "time_table.write.partitionBy(\"year\",\"month\").parquet(\"output/time_table.parquet/\",mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_data = \"input/song_data/*/*/*/*.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_schema = StructType([\n",
    "    StructField(\"artist_id\", StringType()),\n",
    "    StructField(\"artist_latitude\", DoubleType()),\n",
    "    StructField(\"artist_location\", StringType()),\n",
    "    StructField(\"artist_longitude\", StringType()),\n",
    "    StructField(\"artist_name\", StringType()),\n",
    "    StructField(\"duration\", DoubleType()),\n",
    "    StructField(\"num_songs\", IntegerType()),\n",
    "    StructField(\"song_id\", IntegerType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"year\", IntegerType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read in song data to use for songplays table\n",
    "song_df = spark.read.json(song_data,schema=song_schema).drop(\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# extract columns from joined song and log datasets to create songplays table \n",
    "songplays_table = (df.join(song_df, df[\"song\"] == song_df[\"title\"], how='inner')\n",
    "                   .select(monotonically_increasing_id().alias(\"songplay_id\")\n",
    "                           ,col(\"start_time\")\n",
    "                           ,col(\"user_id\")\n",
    "                           ,col(\"level\")\n",
    "                           ,col(\"song_id\")\n",
    "                           ,col(\"artist_id\")\n",
    "                           ,col(\"session_id\")\n",
    "                           ,col(\"location\")\n",
    "                           ,col(\"user_agent\")\n",
    "                           ,col(\"year\")\n",
    "                           ,col(\"month\")\n",
    "                          )\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['songplay_id',\n",
       " 'start_time',\n",
       " 'user_id',\n",
       " 'level',\n",
       " 'song_id',\n",
       " 'artist_id',\n",
       " 'session_id',\n",
       " 'location',\n",
       " 'user_agent',\n",
       " 'year',\n",
       " 'month']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songplays_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write songplays table to parquet files partitioned by year and month\n",
    "songplays_table.write.partitionBy(\"year\",\"month\").parquet(\"output/songplays_table.parquet/\",mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
